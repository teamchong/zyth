#!/usr/bin/env python3
"""100% Training Correctness Verification - PyAOT vs HuggingFace"""

import json
import subprocess
from tokenizers import Tokenizer
from tokenizers.models import BPE
from tokenizers.trainers import BpeTrainer

print("üîç 100% Training Correctness Verification")
print("=" * 70)
print()

VOCAB_SIZE = 2048

# Load benchmark data
with open("benchmark_data.json") as f:
    data = json.load(f)
    corpus = data["texts"]

print(f"Training corpus: {len(corpus)} texts")
print(f"Vocab size: {VOCAB_SIZE}")
print()

#  1. Train with HuggingFace (reference)
print("1Ô∏è‚É£  Training HuggingFace BPE (reference)...")
hf_tokenizer = Tokenizer(BPE())
trainer = BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=[])
hf_tokenizer.train_from_iterator(corpus, trainer=trainer)
hf_tokenizer.save("hf_trained.json")
print("   ‚úÖ Saved to hf_trained.json")
print()

# 2. Train with PyAOT
print("2Ô∏è‚É£  Training PyAOT BPE...")
result = subprocess.run(
    ["./zig-out/bin/bench_train"],
    capture_output=True,
    text=True
)

if result.returncode != 0:
    print(f"   ‚ùå PyAOT training failed!")
    print(f"   Error: {result.stderr}")
    exit(1)

print(f"   ‚úÖ Training time: {result.stdout.strip()}")
print(f"   ‚úÖ Saved to pyaot_trained.json")
print()

# 3. Load both models
print("3Ô∏è‚É£  Loading trained models...")
with open("hf_trained.json") as f:
    hf_model = json.load(f)

with open("pyaot_trained.json") as f:
    pyaot_model = json.load(f)

print("   ‚úÖ Both models loaded")
print()

# 4. Compare vocab
print("4Ô∏è‚É£  Comparing vocabularies...")
hf_vocab = hf_model["model"]["vocab"]
pyaot_vocab = pyaot_model["model"]["vocab"]

print(f"   HuggingFace vocab size: {len(hf_vocab)}")
print(f"   PyAOT vocab size: {len(pyaot_vocab)}")

vocab_match = set(hf_vocab.keys()) == set(pyaot_vocab.keys())
if vocab_match:
    # Also check IDs match
    id_match = all(hf_vocab.get(k) == pyaot_vocab.get(k) for k in hf_vocab.keys())
    if id_match:
        print("   ‚úÖ Vocab 100% MATCH!")
    else:
        print("   ‚ö†Ô∏è  Vocab tokens match but IDs differ")
        vocab_match = False
else:
    print("   ‚ùå Vocab MISMATCH!")
    hf_only = set(hf_vocab.keys()) - set(pyaot_vocab.keys())
    pyaot_only = set(pyaot_vocab.keys()) - set(hf_vocab.keys())
    if hf_only:
        print(f"      HF-only tokens: {len(hf_only)}")
    if pyaot_only:
        print(f"      PyAOT-only tokens: {len(pyaot_only)}")

print()

# 5. Compare merges
print("5Ô∏è‚É£  Comparing merge rules...")
hf_merges = hf_model["model"]["merges"]
pyaot_merges = pyaot_model["model"]["merges"]

print(f"   HuggingFace merges: {len(hf_merges)}")
print(f"   PyAOT merges: {len(pyaot_merges)}")

if len(hf_merges) != len(pyaot_merges):
    print("   ‚ùå Different number of merges!")
    merges_match = False
else:
    # Check if merge order matches
    merges_match = hf_merges == pyaot_merges
    if merges_match:
        print("   ‚úÖ Merges 100% MATCH (order preserved)!")
    else:
        # Count how many match
        matches = sum(1 for i in range(len(hf_merges)) if hf_merges[i] == pyaot_merges[i])
        print(f"   ‚ö†Ô∏è  Merges differ: {matches}/{len(hf_merges)} match")
        merges_match = False

print()

# 6. Test encoding
print("6Ô∏è‚É£  Testing encoding with trained models...")
test_texts = [
    "Hello, world!",
    "The quick brown fox",
    "GPT-4 is awesome! üéâ"
]

hf_enc = Tokenizer.from_file("hf_trained.json")
pyaot_enc = Tokenizer.from_file("pyaot_trained.json")

encoding_match = True
for text in test_texts:
    hf_tokens = hf_enc.encode(text).ids
    pyaot_tokens = pyaot_enc.encode(text).ids

    if hf_tokens == pyaot_tokens:
        print(f"   ‚úÖ '{text[:30]}...' - tokens match")
    else:
        print(f"   ‚ùå '{text[:30]}...' - tokens DIFFER!")
        print(f"      HF: {hf_tokens}")
        print(f"      PyAOT: {pyaot_tokens}")
        encoding_match = False

print()

# Final verdict
print("=" * 70)
if vocab_match and merges_match and encoding_match:
    print("üéâ 100% CORRECT! PyAOT training matches HuggingFace perfectly!")
    print("=" * 70)
    exit(0)
else:
    print("‚ùå VERIFICATION FAILED!")
    print(f"   Vocab: {'‚úÖ' if vocab_match else '‚ùå'}")
    print(f"   Merges: {'‚úÖ' if merges_match else '‚ùå'}")
    print(f"   Encoding: {'‚úÖ' if encoding_match else '‚ùå'}")
    print("=" * 70)
    exit(1)
